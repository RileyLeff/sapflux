# Database and Storage Architecture

This document provides a comprehensive and canonical overview of the data storage layer for the Sapflux pipeline. The architecture is designed to be robust, auditable, and reproducible, forming the foundation for all data processing.

The system consists of two primary components:
1.  **PostgreSQL Database**: The authoritative source for all metadata, configuration, relationships, and historical records. It acts as the "control panel" and ledger for the entire pipeline.
2.  **S3-Compatible Object Storage**: A simple, immutable blob store (e.g., Cloudflare R2 or MinIO) for large file content, such as raw data files, final outputs, and database backups.

## 1. Database Setup

The schema requires the **PostGIS** extension for geospatial data support. This is a one-time operation per database.

```sql
-- Connect to your 'sapflux' database and run this command
CREATE EXTENSION IF NOT EXISTS postgis;
CREATE EXTENSION IF NOT EXISTS btree_gist;
```

## 2. Object Storage Bucket Layout

The object store is organized with a simple prefix-based structure. All objects are considered immutable and are never deleted.

*   **`raw-files/`**: Stores the raw, original datalogger files.
    *   **Object Key Schema**: `raw-files/{file_hash}`
    *   The object name is the `blake3` hash of the file content, ensuring content-addressable storage.

*   **`outputs/`**: Stores the final, processed dataset files generated by successful pipeline runs.
    *   **Object Key Schema**: `outputs/{output_id}.parquet`

*   **`repro-cartridges/`**: Stores the "Reproducibility Cartridge" for each output, enabling full, verifiable reruns of the processing.
    *   **Object Key Schema**: `repro-cartridges/{output_id}.zip`

*   **`assets/`**: Stores static assets like species and site icons for the web GUI.
    *   **Object Key Schema**: `assets/icons/sites/{site_code}.png`, `assets/icons/species/{species_code}.svg`

*   **`backups/`**: Stores periodic and continuous (WAL) database backups.
    *   **Object Key Schema**: Varies by backup tool (e.g., `wal-g`), but will be stored under this prefix.

---

## 3. PostgreSQL Database Schema

The database tables are organized into logical groups that reflect their role in the pipeline.

### Core Auditing & History

These tables form the immutable ledger of all changes and raw data ever introduced to the system.

#### 3.1. Transactions

This table is the central, permanent log of every attempt to change the system's state.

**PostgreSQL Schema (`transactions`)**
```sql
CREATE TYPE transaction_outcome AS ENUM (
    'ACCEPTED',
    'REJECTED'
);

CREATE TABLE IF NOT EXISTS transactions (
    transaction_id  UUID PRIMARY KEY,
    user_id         TEXT NOT NULL,
    message         TEXT,
    attempted_at    TIMESTAMPTZ NOT NULL DEFAULT now(),
    outcome         transaction_outcome NOT NULL,
    receipt         JSONB
);
```

**Rust Struct (`sapflux-repository`)**
```rust
use chrono::{DateTime, Utc};
use serde_json::Value;
use uuid::Uuid;

pub enum TransactionOutcome {
    Accepted,
    Rejected,
}

pub struct Transaction {
    pub transaction_id: Uuid,
    pub user_id: String,
    pub message: Option<String>,
    pub attempted_at: DateTime<Utc>,
    pub outcome: TransactionOutcome,
    pub receipt: Value,
}
```

#### 3.2. Raw Files

The canonical index of all known raw data files, linking an object in the `raw-files/` bucket to its history and status.

**PostgreSQL Schema (`raw_files`)**
```sql
CREATE TABLE IF NOT EXISTS raw_files (
    file_hash           TEXT PRIMARY KEY,
    ingesting_transaction_id UUID NOT NULL REFERENCES transactions(transaction_id),
    ingest_context      JSONB,
    include_in_pipeline BOOLEAN NOT NULL DEFAULT TRUE
);
```

**Rust Struct (`sapflux-repository`)**
```rust
use serde_json::Value;
use uuid::Uuid;

pub struct RawFileRecord {
    pub file_hash: String,
    pub ingesting_transaction_id: Uuid,
    pub ingest_context: Option<Value>,
    pub include_in_pipeline: bool,
}
```

### Pipeline Configuration & Execution

These tables act as the "control panel" for the pipeline, defining available components and tracking their execution.

#### 3.3. Data Formats

An inventory of the data schemas (Rust structs) that serve as contracts between parsers and processing pipelines.

**PostgreSQL Schema (`data_formats`)**
```sql
CREATE TABLE IF NOT EXISTS data_formats (
    data_format_id      UUID PRIMARY KEY,
    code_identifier     TEXT UNIQUE NOT NULL, -- e.g., "sapflow_toa5_hierarchical_v1"
    schema_definition   JSONB
);
```

#### 3.4. Parsers

An inventory of all parser components compiled into the application.

**PostgreSQL Schema (`parsers`)**
```sql
CREATE TABLE IF NOT EXISTS parsers (
    parser_id           UUID PRIMARY KEY,
    code_identifier     TEXT UNIQUE NOT NULL, -- e.g., "sapflow_all_v1"
    version             TEXT NOT NULL,
    output_data_format_id UUID NOT NULL REFERENCES data_formats(data_format_id),
    include_in_pipeline BOOLEAN NOT NULL DEFAULT TRUE
);
```

#### 3.5. Processing Pipelines

Defines the end-to-end processing chains that transform parsed data into final outputs.

**PostgreSQL Schema (`processing_pipelines`)**
```sql
CREATE TABLE IF NOT EXISTS processing_pipelines (
    pipeline_id         UUID PRIMARY KEY,
    code_identifier     TEXT UNIQUE NOT NULL, -- e.g., "standard_v1_dst_fix"
    version             TEXT NOT NULL,
    input_data_format_id UUID NOT NULL REFERENCES data_formats(data_format_id),
    include_in_pipeline BOOLEAN NOT NULL DEFAULT TRUE
);
```

#### 3.6. Runs

Records every execution of a processing pipeline, triggered by a successful transaction.

**PostgreSQL Schema (`runs`)**
```sql
CREATE TYPE run_status AS ENUM (
    'SUCCESS',
    'FAILED'
);

CREATE TABLE IF NOT EXISTS runs (
    run_id              UUID PRIMARY KEY,
    triggering_transaction_id UUID NOT NULL REFERENCES transactions(transaction_id),
    processing_pipeline_id  UUID NOT NULL REFERENCES processing_pipelines(pipeline_id),
    started_at          TIMESTAMPTZ NOT NULL DEFAULT now(),
    finished_at         TIMESTAMPTZ,
    status              run_status NOT NULL,
    -- The exact Git commit hash of the application that executed the run.
    git_commit_hash     TEXT NOT NULL,
    run_log             JSONB
);
```

#### 3.7. Outputs

Links a successful run to its final data product and its reproducibility cartridge.

**PostgreSQL Schema (`outputs`)**
```sql
CREATE TABLE IF NOT EXISTS outputs (
    output_id           UUID PRIMARY KEY,
    run_id              UUID UNIQUE NOT NULL REFERENCES runs(run_id),
    object_store_path   TEXT NOT NULL,
    -- Path to the zip file in the `repro-cartridges/` bucket.
    reproducibility_cartridge_path TEXT NOT NULL,
    row_count           INTEGER,
    is_latest           BOOLEAN NOT NULL DEFAULT FALSE
);
```

**Download Semantics**: The API never streams large objects directly. When `GET /outputs/{id}/download` is called, it issues a short-lived pre-signed URL (15 minute expiry) or a 302 redirect to Cloudflare R2. This keeps the bucket private while enabling clients to download the file without shipping credentials.

**Latest Flag Update Policy**: On every successful insert into `outputs`, the application sets the new row's `is_latest = TRUE` and flips all other rows to `FALSE` within the same database transaction so the flag always identifies the most recent dataset snapshot.

### Project & Geographic Hierarchy

These tables model the real-world physical and organizational structure of the research.

#### 3.8. Projects

A top-level table to group deployments into specific research initiatives.

**PostgreSQL Schema (`projects`)**
```sql
CREATE TABLE IF NOT EXISTS projects (
    project_id          UUID PRIMARY KEY,
    code                TEXT UNIQUE NOT NULL,
    name                TEXT,
    description         TEXT
);
```

**Rust Struct (`sapflux-repository::metadata`)**
```rust
use uuid::Uuid;

pub struct Project {
    pub project_id: Uuid,
    pub code: String,
    pub name: Option<String>,
    pub description: Option<String>,
}
```

#### 3.9. Sites, Zones, and Plots

These tables store the nested physical locations where data is collected.

**PostgreSQL Schemas (`sites`, `zones`, `plots`)**
```sql
CREATE TABLE IF NOT EXISTS sites (
    site_id   UUID PRIMARY KEY,
    code      TEXT UNIQUE NOT NULL,
    name      TEXT,
    timezone  TEXT NOT NULL,
    boundary  GEOMETRY(Polygon, 4326),
    -- Path to icon in `assets/` bucket, e.g., "icons/sites/BVL.png"
    icon_path TEXT
);

CREATE TABLE IF NOT EXISTS zones (
    zone_id   UUID PRIMARY KEY,
    site_id   UUID NOT NULL REFERENCES sites(site_id) ON DELETE CASCADE,
    name      TEXT NOT NULL,
    boundary  GEOMETRY(Polygon, 4326),
    CONSTRAINT uq_zone_site_name UNIQUE (site_id, name)
);

CREATE TABLE IF NOT EXISTS plots (
    plot_id   UUID PRIMARY KEY,
    zone_id   UUID NOT NULL REFERENCES zones(zone_id) ON DELETE CASCADE,
    name      TEXT NOT NULL,
    boundary  GEOMETRY(Polygon, 4326),
    CONSTRAINT uq_plot_zone_name UNIQUE (zone_id, name)
);
```

### Biological & Instrumentation Hierarchy

These tables describe the plants being measured and the equipment used to measure them.

#### 3.10. Species, Plants, and Stems

These tables track the biological hierarchy from species down to individual stems.

**PostgreSQL Schemas (`species`, `plants`, `stems`)**
```sql
CREATE TABLE IF NOT EXISTS species (
    species_id  UUID PRIMARY KEY,
    code        TEXT UNIQUE NOT NULL,
    common_name JSONB,
    latin_name  JSONB,
    -- Path to icon in `assets/` bucket, e.g., "icons/species/PITA.svg"
    icon_path   TEXT
);

CREATE TABLE IF NOT EXISTS plants (
    plant_id   UUID PRIMARY KEY,
    plot_id    UUID NOT NULL REFERENCES plots(plot_id) ON DELETE CASCADE,
    species_id UUID NOT NULL REFERENCES species(species_id),
    code       TEXT NOT NULL,
    location   GEOMETRY(Point, 4326),
    CONSTRAINT uq_plant_plot_code UNIQUE (plot_id, code)
);

CREATE TABLE IF NOT EXISTS stems (
    stem_id   UUID PRIMARY KEY,
    plant_id  UUID NOT NULL REFERENCES plants(plant_id) ON DELETE CASCADE,
    code      TEXT NOT NULL,
    dbh_cm    NUMERIC,
    CONSTRAINT uq_stem_plant_code UNIQUE (plant_id, code)
);
```

#### 3.11. Dataloggers and Sensors

These tables define the types and specific units of hardware used in the field.

**PostgreSQL Schemas (`datalogger_types`, `dataloggers`, `datalogger_aliases`, `sensor_types`, `sensor_thermistor_pairs`)**
```sql
CREATE TABLE IF NOT EXISTS datalogger_types (
    datalogger_type_id UUID PRIMARY KEY,
    code               TEXT UNIQUE NOT NULL,
    name               TEXT,
    icon_path          TEXT
);

CREATE TABLE IF NOT EXISTS dataloggers (
    datalogger_id      UUID PRIMARY KEY,
    datalogger_type_id UUID NOT NULL REFERENCES datalogger_types(datalogger_type_id),
    code               TEXT UNIQUE NOT NULL
);

CREATE TABLE IF NOT EXISTS datalogger_aliases (
    datalogger_alias_id UUID PRIMARY KEY,
    datalogger_id       UUID NOT NULL REFERENCES dataloggers(datalogger_id) ON DELETE CASCADE,
    alias               TEXT NOT NULL,
    active_during       TSTZRANGE NOT NULL,
    CONSTRAINT uq_datalogger_alias UNIQUE (datalogger_id, alias, active_during),
    CONSTRAINT uq_alias_no_overlap EXCLUDE USING gist (
        alias WITH =,
        active_during WITH &&
    ),
    CONSTRAINT uq_alias_no_adjacency EXCLUDE USING gist (
        alias WITH =,
        active_during WITH -|-
    )
);

CREATE TABLE IF NOT EXISTS sensor_types (
    sensor_type_id UUID PRIMARY KEY,
    code           TEXT UNIQUE NOT NULL,
    description    TEXT
);

CREATE TABLE IF NOT EXISTS sensor_thermistor_pairs (
    thermistor_pair_id UUID PRIMARY KEY,
    sensor_type_id     UUID NOT NULL REFERENCES sensor_types(sensor_type_id) ON DELETE CASCADE,
    name               TEXT NOT NULL,
    depth_mm           NUMERIC NOT NULL,
    CONSTRAINT uq_sensor_thermistor_pair_name UNIQUE (sensor_type_id, name)
);
```

**Logger Alias Resolution**: `datalogger_aliases` maintains every alternate ID ever observed in the raw files. Aliases are stored with a `TSTZRANGE`, and exclusion constraints forbid both overlaps and "touching" windows, so back-to-back alias reuse must be separated by a true gap. During metadata enrichment the engine first matches on `dataloggers.code`, then on any alias whose range covers the measurement timestamp. If multiple matches exist (which is prevented by the exclusion constraints) the transaction is rejected.

### The Linking Table

This central table connects all the hierarchies together for a specific period of time.

#### 3.12. Deployments

A deployment represents the installation of a specific sensor onto a specific stem for a defined period, as part of a specific project.

**PostgreSQL Schema (`deployments`)**
```sql
CREATE TABLE IF NOT EXISTS deployments (
    deployment_id       UUID PRIMARY KEY,
    project_id          UUID NOT NULL REFERENCES projects(project_id),
    stem_id             UUID NOT NULL REFERENCES stems(stem_id),
    datalogger_id       UUID NOT NULL REFERENCES dataloggers(datalogger_id),
    sensor_type_id      UUID NOT NULL REFERENCES sensor_types(sensor_type_id),
    sdi_address         TEXT NOT NULL,
    start_timestamp_utc TIMESTAMPTZ NOT NULL,
    end_timestamp_utc   TIMESTAMPTZ,
    installation_metadata JSONB,
    include_in_pipeline BOOLEAN NOT NULL DEFAULT TRUE,
    CONSTRAINT uq_deployment_sensor_time UNIQUE (datalogger_id, sdi_address, start_timestamp_utc)
);

ALTER TABLE deployments
    ADD COLUMN active_during TSTZRANGE GENERATED ALWAYS AS (
        tstzrange(start_timestamp_utc, end_timestamp_utc, '[)')
    ) STORED,
    ADD CONSTRAINT uq_deployment_no_overlap EXCLUDE USING gist (
        datalogger_id WITH =,
        sdi_address WITH =,
        active_during WITH &&
    ),
    ADD CONSTRAINT uq_deployment_no_adjacency EXCLUDE USING gist (
        datalogger_id WITH =,
        sdi_address WITH =,
        active_during WITH -|-
    );
```

The generated `active_during` range ensures there is never more than one active deployment for a `(datalogger, sdi_address)` pair at the same instant. Boundary equality (e.g., one deployment ending exactly when another begins) is also disallowed via the `-|-` exclusion; users must leave a real gap before reactivating the same hardware.

**Rust Struct (`sapflux-repository::metadata`)**
```rust
use chrono::{DateTime, Utc};
use serde_json::Value;
use uuid::Uuid;

#[derive(Debug, Clone, PartialEq)]
pub struct Deployment {
    pub deployment_id: Uuid,
    pub project_id: Uuid,
    pub stem_id: Uuid,
    pub datalogger_id: Uuid,
    pub sensor_type_id: Uuid,
    pub sdi_address: String,
    pub start_timestamp_utc: DateTime<Utc>,
    pub end_timestamp_utc: Option<DateTime<Utc>>,
    pub installation_metadata: Option<Value>,
    pub include_in_pipeline: bool,
}
```

### Calculation Parameters

These tables provide a flexible, hierarchical system for managing the parameters used in sap flux calculations.

#### 3.13. Parameters

A dictionary defining all available parameters that can be used in calculations.

**PostgreSQL Schema (`parameters`)**
```sql
CREATE TABLE IF NOT EXISTS parameters (
    parameter_id        UUID PRIMARY KEY,
    code                TEXT UNIQUE NOT NULL,
    description         TEXT,
    unit                TEXT
);
```

#### 3.14. Parameter Overrides

Stores all context-specific override rules. The most specific (lowest in the list of FKs) matching rule for a given context always wins.

**PostgreSQL Schema (`parameter_overrides`)**
```sql
CREATE TABLE IF NOT EXISTS parameter_overrides (
    override_id         UUID PRIMARY KEY,
    parameter_id        UUID NOT NULL REFERENCES parameters(parameter_id),
    value               JSONB NOT NULL,
    
    -- Foreign keys to specify the context of the override.
    site_id             UUID REFERENCES sites(site_id) ON DELETE CASCADE,
    species_id          UUID REFERENCES species(species_id) ON DELETE CASCADE,
    zone_id             UUID REFERENCES zones(zone_id) ON DELETE CASCADE,
    plot_id             UUID REFERENCES plots(plot_id) ON DELETE CASCADE,
    plant_id            UUID REFERENCES plants(plant_id) ON DELETE CASCADE,
    stem_id             UUID REFERENCES stems(stem_id) ON DELETE CASCADE,
    deployment_id       UUID REFERENCES deployments(deployment_id) ON DELETE CASCADE,
    
    effective_transaction_id UUID NOT NULL REFERENCES transactions(transaction_id),
    
    CONSTRAINT uq_parameter_override_context UNIQUE (
        parameter_id, site_id, species_id, zone_id, plot_id, plant_id, stem_id, deployment_id
    )
);
```

`value` stores a strongly-typed JSON payload (numeric, boolean, or structured) so the cascade can deserialize without lossy string parsing. Examples of canonical payloads are described in `notes/parameter_info.toml`.

### Object Storage Lifecycle

Uploads to Cloudflare R2 are performed idempotently before the database transaction commits. Because the blob store is not part of the database transaction, a failure during commit can leave orphaned objects. These are harmless—future uploads deduplicate by hash—and a periodic garbage-collection job enumerates bucket keys and deletes any object whose hash/path is not referenced by the database.

The same pattern applies to derived artifacts (`outputs/{id}.parquet` and `repro-cartridges/{id}.zip`): write the object first, then persist the database row. If the row insert fails, the orphaned object is cleaned up by the same GC routine.
